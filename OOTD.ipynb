{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a81026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install torch\n",
    "%pip install --upgrade --force-reinstall h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import torch\n",
    "\n",
    "# Load Fashion-MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Define class labels\n",
    "class_names = ['T-shirt/top', 'Pants', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Display information about the dataset\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Test images shape:\", test_images.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize sample images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4730b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load Fashion-MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Define class labels\n",
    "class_names = ['T-shirt/top', 'Pants', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images[..., tf.newaxis] / 255.0\n",
    "test_images = test_images[..., tf.newaxis] / 255.0\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),  # Input layer with specified shape\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Reshape the data for CNN input\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
    "                    steps_per_epoch=int(len(train_images) / 100), epochs=50,\n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='test loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the uploaded image\n",
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    if len(resized_image.shape) == 3:\n",
    "        if resized_image.shape[2] == 3:  # Color image\n",
    "            resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "        resized_image = resized_image / 255.0\n",
    "        # Add batch and channel dimensions\n",
    "        preprocessed_image = resized_image[np.newaxis, ..., np.newaxis]\n",
    "    else:  # Grayscale image\n",
    "        resized_image = resized_image / 255.0\n",
    "        # Add batch and channel dimensions\n",
    "        preprocessed_image = resized_image[np.newaxis, ..., np.newaxis]\n",
    "    return preprocessed_image\n",
    "\n",
    "# Function to predict outfit\n",
    "def predict_outfit(image):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    print(\"Preprocessed image shape:\", preprocessed_image.shape)  # Debugging: Check the shape of the preprocessed image\n",
    "    prediction = model(torch.tensor(preprocessed_image, dtype=torch.float32))\n",
    "    print(\"Prediction shape:\", prediction.shape)  # Debugging: Check the shape of the prediction\n",
    "    predicted_class = tf.argmax(prediction, axis=1).numpy()[0]\n",
    "    predicted_label = class_names[predicted_class]\n",
    "    return predicted_label\n",
    "\n",
    "# Function to get complementary items for the predicted class\n",
    "def get_complementary_items(predicted_label):\n",
    "    complementary_items = {\n",
    "        'T-shirt/top': ['Jeans', 'Sneakers'],\n",
    "        'Pullover': ['Shirt', 'Jeans', 'Sneakers'],\n",
    "        'Shirt': ['Jeans', 'Sneakers', 'Necklace'],\n",
    "        'Dress': ['Shirt', 'Boots'],\n",
    "        'Coat': ['Jeans', 'Sneakers'],\n",
    "        'Sandal': ['Necklace', 'Handbag'],\n",
    "        'Pants': ['Shirt', 'Sneakers'],\n",
    "        'Sneaker': ['T-shirt/top', 'Jeans'],\n",
    "        'Bag': ['Sandals', 'Necklace'],\n",
    "        'Ankle boot': ['Shirt', 'Sneakers']\n",
    "    }\n",
    "    return complementary_items.get(predicted_label, [])\n",
    "\n",
    "\n",
    "# Function to display outfit suggestions\n",
    "def display_outfit_suggestions(predicted_label, outfit_suggestions):\n",
    "    if outfit_suggestions:\n",
    "        print(\"Based on the\", predicted_label, \"you uploaded, we suggest you wear:\")\n",
    "        for suggestion in outfit_suggestions:\n",
    "            print(\"-\", suggestion)\n",
    "    else:\n",
    "        print(\"Sorry, we couldn't provide outfit suggestions for this image.\")\n",
    "\n",
    "        \n",
    "# Function to extract dominant colors using K-means clustering\n",
    "def extract_dominant_colors(image, k=3):\n",
    "    # Reshape image to a 2D array of pixels\n",
    "    pixels = image.reshape((-1, 3))\n",
    "    pixels = np.float32(pixels)\n",
    "\n",
    "    # Define criteria and apply K-means\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.85)  # Adjusting epsilon\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Convert centers to uint8 and return\n",
    "    centers = np.uint8(centers)\n",
    "    return centers\n",
    "\n",
    "# Function to recognize color category\n",
    "def recognize_color(centers):\n",
    "    # Define color categories (you can extend this)\n",
    "    color_categories = {\n",
    "        (0, 0, 255): 'Red',\n",
    "        (0, 255, 0): 'Green',\n",
    "        (255, 0, 0): 'Blue',\n",
    "        (255, 255, 255): 'White',\n",
    "        (0, 0, 0): 'Black',\n",
    "        (255, 255, 0): 'Yellow',\n",
    "        (255, 0, 255): 'Magenta',\n",
    "        (0, 255, 255): 'Cyan',\n",
    "        (128, 0, 0): 'Maroon',\n",
    "        (0, 128, 0): 'Green (Dark)',\n",
    "        (0, 0, 128): 'Navy',\n",
    "        (128, 128, 0): 'Olive',\n",
    "        (128, 0, 128): 'Purple',\n",
    "        (0, 128, 128): 'Teal',\n",
    "        (128, 128, 128): 'Gray',\n",
    "        (192, 192, 192): 'Silver',\n",
    "        (128, 128, 255): 'Light Blue',\n",
    "        (128, 0, 255): 'Violet',\n",
    "        (255, 128, 128): 'Pink',\n",
    "        (128, 255, 128): 'Light Green',\n",
    "        (255, 128, 0): 'Orange',\n",
    "        (255, 0, 128): 'Rose',\n",
    "        (0, 128, 255): 'Sky Blue',\n",
    "        (0, 255, 128): 'Spring Green',\n",
    "        (255, 128, 255): 'Orchid',\n",
    "        (255, 255, 128): 'Beige',\n",
    "        (128, 255, 255): 'Turquoise',\n",
    "        (255, 128, 128): 'Coral',\n",
    "        (128, 255, 128): 'Mint',\n",
    "        (128, 128, 255): 'Periwinkle',\n",
    "        (255, 128, 255): 'Fuchsia',\n",
    "        (255, 255, 128): 'Peach',\n",
    "        (128, 255, 255): 'Aquamarine',\n",
    "        (255, 128, 192): 'Salmon',\n",
    "        (255, 192, 128): 'Apricot',\n",
    "        (192, 255, 128): 'Lime',\n",
    "        (128, 192, 255): 'Light Purple',\n",
    "        (192, 128, 255): 'Lavender',\n",
    "        (255, 192, 255): 'Lilac',\n",
    "        (255, 255, 192): 'Light Yellow',\n",
    "        (192, 255, 255): 'Sky',\n",
    "        (255, 192, 192): 'Rose Pink',\n",
    "        (192, 255, 192): 'Light Green',\n",
    "        (192, 192, 255): 'Light Purple',\n",
    "        (255, 255, 255): 'White',\n",
    "        (0, 0, 0): 'Black'\n",
    "    }\n",
    "\n",
    "    # Find the closest color category to each center\n",
    "    recognized_colors = []\n",
    "    for center in centers:\n",
    "        closest_color = min(color_categories, key=lambda x: np.linalg.norm(np.array(x) - center))\n",
    "        recognized_colors.append(color_categories[closest_color])\n",
    "\n",
    "    return recognized_colors\n",
    "\n",
    "# Function to suggest complementary colors based on recognized color\n",
    "def suggest_complementary_colors(recognized_colors):\n",
    "    complementary_colors = {\n",
    "    'Red': ['Cyan', 'Green', 'Blue'],\n",
    "    'Green': ['Magenta', 'Red', 'Blue'],\n",
    "    'Blue': ['Yellow', 'Red', 'Green'],\n",
    "    'Yellow': ['Blue', 'Magenta', 'Cyan'],\n",
    "    'Magenta': ['Green', 'Yellow', 'Cyan'],\n",
    "    'Cyan': ['Red', 'Magenta', 'Yellow'],\n",
    "    'White': ['Black'],\n",
    "    'Black': ['White'],\n",
    "    'Orange': ['Blue', 'Purple'],\n",
    "    'Purple': ['Yellow', 'Orange'],\n",
    "    'Pink': ['Green', 'Turquoise'],\n",
    "    'Turquoise': ['Pink', 'Orange'],\n",
    "}\n",
    "\n",
    "\n",
    "    return complementary_colors.get(recognized_colors[0], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f9824",
   "metadata": {},
   "source": [
    "### Upload Your Own Clothing Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image from the specified file path\n",
    "file_path = r\"USER/Image.png\" #REPLACE WITH YOUR USER IMAGE PATH HERE\n",
    "image = cv2.imread(file_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is not None:\n",
    "    # Process the loaded image\n",
    "    predicted_label = predict_outfit(image)\n",
    "    outfit_suggestions = get_complementary_items(predicted_label)\n",
    "    display_outfit_suggestions(predicted_label, outfit_suggestions)\n",
    "    # Extract dominant colors\n",
    "    dominant_colors = extract_dominant_colors(image)\n",
    "\n",
    "    # Recognize color\n",
    "    recognized_colors = recognize_color(dominant_colors)\n",
    "\n",
    "    # Suggest complementary colors\n",
    "    complementary_colors = suggest_complementary_colors(recognized_colors)\n",
    "\n",
    "    # Display suggestions\n",
    "    print(\"Recognized color:\", recognized_colors[0])\n",
    "    print(\"Complementary colors:\", complementary_colors)\n",
    "else:\n",
    "    print(\"Error: Unable to load the image from the specified path.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
